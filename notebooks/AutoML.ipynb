{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URqgW7TwCaP8"
   },
   "source": [
    "# Auto ML\n",
    "Antonio Karam (akaram@nd.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJQzI55vCaP9"
   },
   "source": [
    "## Task 1: Data Selection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XlbrJSBECaP9",
    "outputId": "fb68d403-efe0-45a7-bdde-baa49f43c4a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X, y), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape data (flatten the 28x28 images into vectors of size 784)\n",
    "X = X.reshape(-1, 28 * 28)\n",
    "X_test = X_test.reshape(-1, 28 * 28)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Split the data further into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_UmIrbtCaP-"
   },
   "source": [
    "## Task 2: Manual Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnqqC6H_CaP-"
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjpXE7ebCaP-",
    "outputId": "7881d0cc-209b-42f9-98d9-a7aad2c41f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NN with Learning Rate: 0.001, Batch Size: 16, Epochs: 10...\n",
      "Completed: Test Accuracy: 0.9614999890327454, Test Loss: 0.3772837221622467\n",
      "Training NN with Learning Rate: 0.001, Batch Size: 16, Epochs: 50...\n",
      "Completed: Test Accuracy: 0.9688000082969666, Test Loss: 1.3858526945114136\n",
      "Training NN with Learning Rate: 0.001, Batch Size: 16, Epochs: 100...\n",
      "Completed: Test Accuracy: 0.9677000045776367, Test Loss: 2.3701331615448\n",
      "Training NN with Learning Rate: 0.001, Batch Size: 32, Epochs: 10...\n",
      "Completed: Test Accuracy: 0.9682000279426575, Test Loss: 0.3021455705165863\n",
      "Training NN with Learning Rate: 0.001, Batch Size: 32, Epochs: 50...\n",
      "Completed: Test Accuracy: 0.970300018787384, Test Loss: 0.6615756750106812\n",
      "Training NN with Learning Rate: 0.001, Batch Size: 32, Epochs: 100...\n",
      "Completed: Test Accuracy: 0.9703999757766724, Test Loss: 1.3794604539871216\n",
      "Training NN with Learning Rate: 0.001, Batch Size: 64, Epochs: 10...\n",
      "Completed: Test Accuracy: 0.9656999707221985, Test Loss: 0.20762908458709717\n",
      "Training NN with Learning Rate: 0.001, Batch Size: 64, Epochs: 50...\n",
      "Completed: Test Accuracy: 0.9726999998092651, Test Loss: 0.4159495532512665\n",
      "Training NN with Learning Rate: 0.001, Batch Size: 64, Epochs: 100...\n",
      "Completed: Test Accuracy: 0.9713000059127808, Test Loss: 0.6500171422958374\n",
      "Training NN with Learning Rate: 0.01, Batch Size: 16, Epochs: 10...\n",
      "Completed: Test Accuracy: 0.9527000188827515, Test Loss: 15.445878028869629\n",
      "Training NN with Learning Rate: 0.01, Batch Size: 16, Epochs: 50...\n",
      "Completed: Test Accuracy: 0.958899974822998, Test Loss: 160.1164093017578\n",
      "Training NN with Learning Rate: 0.01, Batch Size: 16, Epochs: 100...\n",
      "Completed: Test Accuracy: 0.9642999768257141, Test Loss: 256.6732177734375\n",
      "Training NN with Learning Rate: 0.01, Batch Size: 32, Epochs: 10...\n",
      "Completed: Test Accuracy: 0.9614999890327454, Test Loss: 6.552171230316162\n",
      "Training NN with Learning Rate: 0.01, Batch Size: 32, Epochs: 50...\n",
      "Completed: Test Accuracy: 0.9657999873161316, Test Loss: 45.59523010253906\n",
      "Training NN with Learning Rate: 0.01, Batch Size: 32, Epochs: 100...\n",
      "Completed: Test Accuracy: 0.9646000266075134, Test Loss: 122.69251251220703\n",
      "Training NN with Learning Rate: 0.01, Batch Size: 64, Epochs: 10...\n",
      "Completed: Test Accuracy: 0.9549000263214111, Test Loss: 3.0279204845428467\n",
      "Training NN with Learning Rate: 0.01, Batch Size: 64, Epochs: 50...\n",
      "Completed: Test Accuracy: 0.9423999786376953, Test Loss: 36.78744888305664\n",
      "Training NN with Learning Rate: 0.01, Batch Size: 64, Epochs: 100...\n",
      "Completed: Test Accuracy: 0.9690999984741211, Test Loss: 52.96028137207031\n",
      "Training NN with Learning Rate: 0.1, Batch Size: 16, Epochs: 10...\n",
      "Completed: Test Accuracy: 0.9254000186920166, Test Loss: 3201.4716796875\n",
      "Training NN with Learning Rate: 0.1, Batch Size: 16, Epochs: 50...\n",
      "Completed: Test Accuracy: 0.9610999822616577, Test Loss: 7965.47265625\n",
      "Training NN with Learning Rate: 0.1, Batch Size: 16, Epochs: 100...\n",
      "Completed: Test Accuracy: 0.9631999731063843, Test Loss: 24086.888671875\n",
      "Training NN with Learning Rate: 0.1, Batch Size: 32, Epochs: 10...\n",
      "Completed: Test Accuracy: 0.9545999765396118, Test Loss: 1075.3477783203125\n",
      "Training NN with Learning Rate: 0.1, Batch Size: 32, Epochs: 50...\n",
      "Completed: Test Accuracy: 0.9650999903678894, Test Loss: 4951.54931640625\n",
      "Training NN with Learning Rate: 0.1, Batch Size: 32, Epochs: 100...\n",
      "Completed: Test Accuracy: 0.965499997138977, Test Loss: 12135.6513671875\n",
      "Training NN with Learning Rate: 0.1, Batch Size: 64, Epochs: 10...\n",
      "Completed: Test Accuracy: 0.9473000168800354, Test Loss: 282.9524841308594\n",
      "Training NN with Learning Rate: 0.1, Batch Size: 64, Epochs: 50...\n",
      "Completed: Test Accuracy: 0.9670000076293945, Test Loss: 1590.138916015625\n",
      "Training NN with Learning Rate: 0.1, Batch Size: 64, Epochs: 100...\n",
      "Completed: Test Accuracy: 0.9653000235557556, Test Loss: 6830.53125\n",
      "Best NN - Learning Rate: 0.001, Batch Size: 64, Epochs: 50, Accuracy: 0.9726999998092651, Loss: 0.4159495532512665\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to create the model\n",
    "def create_model(learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28 * 28,)))  # Flatten the input\n",
    "    model.add(Dense(128, activation='relu'))  # Hidden layer\n",
    "    model.add(Dense(10, activation='softmax'))  # Output layer\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Hyperparameter combinations\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [16, 32, 64]\n",
    "epochs = [10, 50, 100]\n",
    "\n",
    "# Record results\n",
    "results_nn = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for ep in epochs:\n",
    "            print(f'Training NN with Learning Rate: {lr}, Batch Size: {bs}, Epochs: {ep}...')\n",
    "            # Create and train the model\n",
    "            model = create_model(learning_rate=lr)\n",
    "            history = model.fit(X_train, y_train, epochs=ep, batch_size=bs, validation_split=0.2, verbose=0)\n",
    "\n",
    "            # Evaluate on test set\n",
    "            test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "            results_nn.append((lr, bs, ep, test_accuracy, test_loss))\n",
    "            print(f'Completed: Test Accuracy: {test_accuracy}, Test Loss: {test_loss}')\n",
    "\n",
    "# Find the best result\n",
    "best_nn = max(results_nn, key=lambda x: x[3])  # max by accuracy\n",
    "print(f'Best NN - Learning Rate: {best_nn[0]}, Batch Size: {best_nn[1]}, Epochs: {best_nn[2]}, Accuracy: {best_nn[3]}, Loss: {best_nn[4]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pf1whEfgCaP_"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BB2HRkQCaP_",
    "outputId": "8dd4d0d7-6ca6-4874-caf6-e7939778c709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.8495\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.8495\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.8495\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.8496\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.8495\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.8495\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.8495\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.8496\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.8495\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.8495\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.8495\n",
      "Training RF with n_estimators: 50, max_depth: 5, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.8496\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9454\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9461\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9452\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9438\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9463\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9461\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9452\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9438\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9454\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9452\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9477\n",
      "Training RF with n_estimators: 50, max_depth: 10, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9438\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9657\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9626\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9607\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.956\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9622\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9639\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9607\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.956\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9625\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9637\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9612\n",
      "Training RF with n_estimators: 50, max_depth: 20, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.956\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9644\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9646\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9617\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9549\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9656\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9644\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9617\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9549\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9623\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9636\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9599\n",
      "Training RF with n_estimators: 50, max_depth: None, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9549\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.8599\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.8599\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.8596\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.8595\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.8599\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.8599\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.8596\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.8595\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.8599\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.8599\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.8601\n",
      "Training RF with n_estimators: 100, max_depth: 5, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.8595\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9471\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9467\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9476\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9466\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9477\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9482\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9476\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9466\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9472\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9467\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.947\n",
      "Training RF with n_estimators: 100, max_depth: 10, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9466\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9678\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9645\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9623\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9581\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9656\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9651\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9623\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9581\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9673\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9637\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9635\n",
      "Training RF with n_estimators: 100, max_depth: 20, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9581\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9685\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9658\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9626\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9559\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.968\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9657\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9626\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9559\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9645\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9653\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9619\n",
      "Training RF with n_estimators: 100, max_depth: None, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9559\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.8635\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.8638\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.8638\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.8639\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.8635\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.8638\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.8638\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.8639\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.8635\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.8638\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.864\n",
      "Training RF with n_estimators: 200, max_depth: 5, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.8639\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9489\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9478\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9476\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9466\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9486\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9472\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9476\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9466\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9483\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9478\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9479\n",
      "Training RF with n_estimators: 200, max_depth: 10, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9466\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9698\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9663\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9624\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9582\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9674\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9663\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9624\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9582\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9663\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9657\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9631\n",
      "Training RF with n_estimators: 200, max_depth: 20, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9582\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 2, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9685\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 2, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9671\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 2, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9636\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 2, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9563\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 5, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9697\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 5, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.967\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 5, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9636\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 5, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9563\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 10, min_samples_leaf: 1...\n",
      "Completed: Random Forest Accuracy: 0.9654\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 10, min_samples_leaf: 2...\n",
      "Completed: Random Forest Accuracy: 0.9664\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 10, min_samples_leaf: 4...\n",
      "Completed: Random Forest Accuracy: 0.9622\n",
      "Training RF with n_estimators: 200, max_depth: None, min_samples_split: 10, min_samples_leaf: 10...\n",
      "Completed: Random Forest Accuracy: 0.9563\n",
      "Best RF - n_estimators: 200, max_depth: 20, min_samples_split: 2, min_samples_leaf: 1, Accuracy: 0.9698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Hyperparameter combinations\n",
    "n_estimators = [50, 100, 200]\n",
    "max_depths = [5, 10, 20, None]\n",
    "min_samples_splits = [2, 5, 10]\n",
    "min_samples_leaves = [1, 2, 4, 10]\n",
    "\n",
    "# Record results\n",
    "results_rf = []\n",
    "\n",
    "for n in n_estimators:\n",
    "    for depth in max_depths:\n",
    "        for split in min_samples_splits:\n",
    "            for leaf in min_samples_leaves:\n",
    "                print(f'Training RF with n_estimators: {n}, max_depth: {depth}, min_samples_split: {split}, min_samples_leaf: {leaf}...')\n",
    "                # Create and train the model\n",
    "                rf = RandomForestClassifier(n_estimators=n, max_depth=depth, min_samples_split=split, min_samples_leaf=leaf, random_state=42)\n",
    "                rf.fit(X_train, y_train)\n",
    "\n",
    "                # Evaluate on test set\n",
    "                y_pred = rf.predict(X_test_scaled)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                results_rf.append((n, depth, split, leaf, accuracy))\n",
    "                print(f'Completed: Random Forest Accuracy: {accuracy}')\n",
    "\n",
    "# Find the best result\n",
    "best_rf = max(results_rf, key=lambda x: x[4])  # max by accuracy\n",
    "print(f'Best RF - n_estimators: {best_rf[0]}, max_depth: {best_rf[1]}, min_samples_split: {best_rf[2]}, min_samples_leaf: {best_rf[3]}, Accuracy: {best_rf[4]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzAuk1P8CaP_"
   },
   "source": [
    "## Task 3: AutoML for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-QoZxiHX3BV"
   },
   "source": [
    "### Neural Network Tuning with TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoKItc_uRR5x",
    "outputId": "3cda6116-5aa7-4f38-831d-a9bf1bd32ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.6 alembic-1.13.3 colorlog-6.9.0 greenlet-3.1.1 optuna-4.0.0 sqlalchemy-2.0.36\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "a4ba1ed4fb3442c290209f13adf1850d",
      "880dba2e71fc4e8e9a90e24c52db4dc7",
      "86c1f4e119d44ffca93d64bf73f5b648",
      "70d6fabe74dd467ca926aeac6bdc8443",
      "215fd0c5a0f34aba9305e17ebe146900",
      "af58677f8e3d4ba1b586e22b28e73e3c",
      "ece64de836c34ce2b32d45740e1dcae3",
      "8d83631641cf4314a4a622a63f98d000",
      "927d359c2cf44e66b3201efdcaf37469",
      "5383d486546e419eaf8a1d544d5ae4e0",
      "668cb7fdede7436ca0464e1c01d8038a"
     ]
    },
    "id": "SKEvwBrZX_UE",
    "outputId": "a88091b6-8c68-4fd2-9e9d-afb258a9ab32"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ba1ed4fb3442c290209f13adf1850d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/40 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9578125000000002\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import numpy as np\n",
    "\n",
    "# Initialize TPOT\n",
    "tpot = TPOTClassifier(verbosity=2, generations=5, population_size=20, random_state=42, config_dict='TPOT NN')\n",
    "\n",
    "# Fit TPOT to the training data\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_tpot = tpot.predict(X_test)\n",
    "y_pred_proba_tpot = tpot.predict_proba(X_test)  # Get probabilities for log loss\n",
    "\n",
    "# Evaluate TPOT model performance\n",
    "accuracy_tpot = accuracy_score(y_test, y_pred_tpot)\n",
    "loss_tpot = log_loss(y_test, y_pred_proba_tpot)\n",
    "print(f'TPOT Model Accuracy: {accuracy_tpot}, Loss: {loss_tpot}')\n",
    "\n",
    "# Export the best model pipeline\n",
    "tpot.export('best_tpot_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl41qht5hqou"
   },
   "source": [
    "### Random Forest Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQo-iU-zhrXB"
   },
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gnm15tehzZj"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define objective function for optimization\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_optuna = rf.predict(X_test)\n",
    "\n",
    "    # Return accuracy for Optuna to maximize\n",
    "    return accuracy_score(y_test, y_pred_optuna)\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(f\"Best Optuna Parameters: {study.best_params}\")\n",
    "print(f\"Best Optuna Accuracy: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWg-TuAxCaQA"
   },
   "source": [
    "## Task 4: Comparative Analysis and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jr_GssxsCaQA"
   },
   "source": [
    "Note: no \"loss\" metric for random forest (manual or optuna)\n",
    "\n",
    "### Comparative Table\n",
    "\n",
    "| Model                | Method     | Best Accuracy | Loss   | Training Time |\n",
    "|----------------------|------------|---------------|--------|---------------|\n",
    "| Neural Network       | Manual     | 0.9727       | 0.4159 | 1 hr 32 min   |\n",
    "| Neural Network       | TPOT     | —       | —      | —      |\n",
    "| Random Forest        | Manual     | 0.9698       | N.A      | 2 hrs         |\n",
    "| Random Forest        | Optuna       | —      | N.A      | —       |\n",
    "\n",
    "### Analysis\n",
    "\n",
    "- **Efficiency**:  \n",
    "  - Manual tuning was time-intensive, particularly for the neural network, but it led to a high accuracy.\n",
    "  - AutoML techniques such as Optuna and TPOT reduced tuning time considerably but resulted in mixed accuracy outcomes compared to manual tuning.\n",
    "\n",
    "- **Strengths and Weaknesses**:\n",
    "  - **Manual Tuning**:\n",
    "    - **Strengths**: Greater control over the process; potentially higher accuracy when fine-tuned.\n",
    "    - **Weaknesses**: Requires expertise and significant time; prone to human error in selecting combinations.\n",
    "\n",
    "  - **AutoML**:\n",
    "    - **Strengths**: Faster and less labor-intensive; reduces need for domain expertise.\n",
    "    - **Weaknesses**: Potentially lower accuracy; limited flexibility in certain parameters.\n",
    "\n",
    "AutoML seems like a great idea for much more complex models and problems that have varied hyperparamters. However, for a dataset like MNIST, which is well studied and simple, AutoML can be overkill, and as we see in the neural network, it did not do as well as anticipated."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "r_UmIrbtCaP-",
    "pf1whEfgCaP_"
   ],
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "215fd0c5a0f34aba9305e17ebe146900": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5383d486546e419eaf8a1d544d5ae4e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "668cb7fdede7436ca0464e1c01d8038a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70d6fabe74dd467ca926aeac6bdc8443": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5383d486546e419eaf8a1d544d5ae4e0",
      "placeholder": "​",
      "style": "IPY_MODEL_668cb7fdede7436ca0464e1c01d8038a",
      "value": " 38/40 [1:27:09&lt;03:18, 99.23s/pipeline]"
     }
    },
    "86c1f4e119d44ffca93d64bf73f5b648": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d83631641cf4314a4a622a63f98d000",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_927d359c2cf44e66b3201efdcaf37469",
      "value": 38
     }
    },
    "880dba2e71fc4e8e9a90e24c52db4dc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af58677f8e3d4ba1b586e22b28e73e3c",
      "placeholder": "​",
      "style": "IPY_MODEL_ece64de836c34ce2b32d45740e1dcae3",
      "value": "Optimization Progress:  95%"
     }
    },
    "8d83631641cf4314a4a622a63f98d000": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "927d359c2cf44e66b3201efdcaf37469": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4ba1ed4fb3442c290209f13adf1850d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_880dba2e71fc4e8e9a90e24c52db4dc7",
       "IPY_MODEL_86c1f4e119d44ffca93d64bf73f5b648",
       "IPY_MODEL_70d6fabe74dd467ca926aeac6bdc8443"
      ],
      "layout": "IPY_MODEL_215fd0c5a0f34aba9305e17ebe146900"
     }
    },
    "af58677f8e3d4ba1b586e22b28e73e3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ece64de836c34ce2b32d45740e1dcae3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
